"""
åŸºäºå›¾RAGçš„æ™ºèƒ½çƒ¹é¥ªåŠ©æ‰‹ - ä¸»ç¨‹åº
æ•´åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGæ£€ç´¢ï¼Œå®ç°çœŸæ­£çš„å›¾æ•°æ®ä¼˜åŠ¿
"""

import os
import sys
import time
import logging
from datetime import datetime
from typing import List, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from dotenv import load_dotenv
from config import DEFAULT_CONFIG, GraphRAGConfig
from rag_modules import (
    GraphDataPreparationModule,
    MilvusIndexConstructionModule, 
    GenerationIntegrationModule
)
from rag_modules.hybrid_retrieval import HybridRetrievalModule
from rag_modules.graph_rag_retrieval import GraphRAGRetrieval
from rag_modules.intelligent_query_router import IntelligentQueryRouter, QueryAnalysis

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class AdvancedGraphRAGSystem:
    """
    å›¾RAGç³»ç»Ÿ
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. æ™ºèƒ½è·¯ç”±ï¼šè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥
    2. åŒå¼•æ“æ£€ç´¢ï¼šä¼ ç»Ÿæ··åˆæ£€ç´¢ + å›¾RAGæ£€ç´¢
    3. å›¾ç»“æ„æ¨ç†ï¼šå¤šè·³éå†ã€å­å›¾æå–ã€å…³ç³»æ¨ç†
    4. æŸ¥è¯¢å¤æ‚åº¦åˆ†æï¼šæ·±åº¦ç†è§£ç”¨æˆ·æ„å›¾
    5. è‡ªé€‚åº”å­¦ä¹ ï¼šåŸºäºåé¦ˆä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
    """
    
    def __init__(self, config: Optional[GraphRAGConfig] = None):
        self.config = config or DEFAULT_CONFIG
        
        # æ ¸å¿ƒæ¨¡å—
        self.data_module = None
        self.index_module = None
        self.generation_module = None
        
        # æ£€ç´¢å¼•æ“
        self.traditional_retrieval = None
        self.graph_rag_retrieval = None
        self.query_router = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.system_ready = False

        # ğŸš€ ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿ - é’ˆå¯¹æ¯ä¸ªèŠå¤©çª—å£ç‹¬ç«‹ç¼“å­˜
        self.session_caches = {}  # æŒ‰session_idåˆ†ç»„çš„ç¼“å­˜ï¼š{session_id: {query: response}}
        self.session_embeddings = {}  # æŒ‰session_idåˆ†ç»„çš„å‘é‡ï¼š{session_id: {query: embedding}}
        self.session_contexts = {}  # æŒ‰session_idåˆ†ç»„çš„ä¸Šä¸‹æ–‡ï¼š{session_id: [messages]}
        self.cache_threshold = 0.75  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
        self.max_session_cache_size = 50  # æ¯ä¸ªä¼šè¯æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        self.max_context_length = 10  # æ¯ä¸ªä¼šè¯ä¿ç•™çš„æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°
        
    def initialize_system(self):
        """åˆå§‹åŒ–é«˜çº§å›¾RAGç³»ç»Ÿ"""
        logger.info("å¯åŠ¨é«˜çº§å›¾RAGç³»ç»Ÿ...")
        
        try:
            # 1. æ•°æ®å‡†å¤‡æ¨¡å—
            print("åˆå§‹åŒ–æ•°æ®å‡†å¤‡æ¨¡å—...")
            self.data_module = GraphDataPreparationModule(
                uri=self.config.neo4j_uri,
                user=self.config.neo4j_user,
                password=self.config.neo4j_password,
                database=self.config.neo4j_database
            )
            
            # 2. å‘é‡ç´¢å¼•æ¨¡å—
            print("åˆå§‹åŒ–Milvuså‘é‡ç´¢å¼•...")
            self.index_module = MilvusIndexConstructionModule(
                host=self.config.milvus_host,
                port=self.config.milvus_port,
                collection_name=self.config.milvus_collection_name,
                dimension=self.config.milvus_dimension,
                model_name=self.config.embedding_model
            )
            
            # 3. ç”Ÿæˆæ¨¡å—
            print("åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—...")
            self.generation_module = GenerationIntegrationModule(
                model_name=self.config.llm_model,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens
            )
            
            # 4. ä¼ ç»Ÿæ··åˆæ£€ç´¢æ¨¡å—
            print("åˆå§‹åŒ–ä¼ ç»Ÿæ··åˆæ£€ç´¢...")
            self.traditional_retrieval = HybridRetrievalModule(
                config=self.config,
                milvus_module=self.index_module,
                data_module=self.data_module,
                llm_client=self.generation_module.client
            )
            
            # 5. å›¾RAGæ£€ç´¢æ¨¡å—
            print("åˆå§‹åŒ–å›¾RAGæ£€ç´¢å¼•æ“...")
            self.graph_rag_retrieval = GraphRAGRetrieval(
                config=self.config,
                llm_client=self.generation_module.client
            )
            
            # 6. æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨
            print("åˆå§‹åŒ–æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨...")
            self.query_router = IntelligentQueryRouter(
                traditional_retrieval=self.traditional_retrieval,
                graph_rag_retrieval=self.graph_rag_retrieval,
                llm_client=self.generation_module.client,
                config=self.config
            )
            
            print("âœ… é«˜çº§å›¾RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        print("\næ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€...")
        
        try:
            # æ£€æŸ¥Milvusé›†åˆæ˜¯å¦å­˜åœ¨
            if self.index_module.has_collection():
                print("âœ… å‘ç°å·²å­˜åœ¨çš„çŸ¥è¯†åº“ï¼Œå°è¯•åŠ è½½...")
                if self.index_module.load_collection():
                    print("çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼")
                    
                    # é‡è¦ï¼šå³ä½¿ä»å·²å­˜åœ¨çš„çŸ¥è¯†åº“åŠ è½½ï¼Œä¹Ÿéœ€è¦åŠ è½½å›¾æ•°æ®ä»¥æ”¯æŒå›¾ç´¢å¼•
                    print("åŠ è½½å›¾æ•°æ®ä»¥æ”¯æŒå›¾æ£€ç´¢...")
                    self.data_module.load_graph_data()
                    print("æ„å»ºèœè°±æ–‡æ¡£...")
                    self.data_module.build_recipe_documents()
                    print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
                    chunks = self.data_module.chunk_documents(
                        chunk_size=self.config.chunk_size,
                        chunk_overlap=self.config.chunk_overlap
                    )
                    
                    self._initialize_retrievers(chunks)
                    return
                else:
                    print("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œå¼€å§‹é‡å»º...")
            
            print("æœªæ‰¾åˆ°å·²å­˜åœ¨çš„é›†åˆï¼Œå¼€å§‹æ„å»ºæ–°çš„çŸ¥è¯†åº“...")
            
            # ä»Neo4jåŠ è½½å›¾æ•°æ®
            print("ä»Neo4jåŠ è½½å›¾æ•°æ®...")
            self.data_module.load_graph_data()
            
            # æ„å»ºèœè°±æ–‡æ¡£
            print("æ„å»ºèœè°±æ–‡æ¡£...")
            self.data_module.build_recipe_documents()
            
            # è¿›è¡Œæ–‡æ¡£åˆ†å—
            print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
            chunks = self.data_module.chunk_documents(
                chunk_size=self.config.chunk_size,
                chunk_overlap=self.config.chunk_overlap
            )
            
            # æ„å»ºMilvuså‘é‡ç´¢å¼•
            print("æ„å»ºMilvuså‘é‡ç´¢å¼•...")
            if not self.index_module.build_vector_index(chunks):
                raise Exception("æ„å»ºå‘é‡ç´¢å¼•å¤±è´¥")
            
            # åˆå§‹åŒ–æ£€ç´¢å™¨
            self._initialize_retrievers(chunks)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            self._show_knowledge_base_stats()
            
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            raise
    
    def _initialize_retrievers(self, chunks: List = None):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        print("åˆå§‹åŒ–æ£€ç´¢å¼•æ“...")
        
        # å¦‚æœæ²¡æœ‰chunksï¼Œä»æ•°æ®æ¨¡å—è·å–
        if chunks is None:
            chunks = self.data_module.chunks or []
        
        # åˆå§‹åŒ–ä¼ ç»Ÿæ£€ç´¢å™¨
        self.traditional_retrieval.initialize(chunks)
        
        # åˆå§‹åŒ–å›¾RAGæ£€ç´¢å™¨
        self.graph_rag_retrieval.initialize()
        
        self.system_ready = True
        print("âœ… æ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆï¼")
    
    def _show_knowledge_base_stats(self):
        """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nçŸ¥è¯†åº“ç»Ÿè®¡:")
        
        # æ•°æ®ç»Ÿè®¡
        stats = self.data_module.get_statistics()
        print(f"   èœè°±æ•°é‡: {stats.get('total_recipes', 0)}")
        print(f"   é£Ÿææ•°é‡: {stats.get('total_ingredients', 0)}")
        print(f"   çƒ¹é¥ªæ­¥éª¤: {stats.get('total_cooking_steps', 0)}")
        print(f"   æ–‡æ¡£æ•°é‡: {stats.get('total_documents', 0)}")
        print(f"   æ–‡æœ¬å—æ•°: {stats.get('total_chunks', 0)}")
        
        # Milvusç»Ÿè®¡
        milvus_stats = self.index_module.get_collection_stats()
        print(f"   å‘é‡ç´¢å¼•: {milvus_stats.get('row_count', 0)} æ¡è®°å½•")
        
        # å›¾RAGç»Ÿè®¡
        route_stats = self.query_router.get_route_statistics()
        print(f"   è·¯ç”±ç»Ÿè®¡: æ€»æŸ¥è¯¢ {route_stats.get('total_queries', 0)} æ¬¡")
        
        if stats.get('categories'):
            categories = list(stats['categories'].keys())[:10]
            print(f"   ğŸ·ï¸ ä¸»è¦åˆ†ç±»: {', '.join(categories)}")
    
    def ask_question_with_routing(self, question: str, stream: bool = False, explain_routing: bool = False):
        """
        æ™ºèƒ½é—®ç­”ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥
        """
        if not self.system_ready:
            raise ValueError("ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†åº“")
            
        print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {question}")
        
        # æ˜¾ç¤ºè·¯ç”±å†³ç­–è§£é‡Šï¼ˆå¯é€‰ï¼‰
        if explain_routing:
            explanation = self.query_router.explain_routing_decision(question)
            print(explanation)
        
        start_time = time.time()
        
        try:
            # 1. æ™ºèƒ½è·¯ç”±æ£€ç´¢
            print("æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢è·¯ç”±...")
            relevant_docs, analysis = self.query_router.route_query(question, self.config.top_k)
            
            # 2. æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯
            strategy_icons = {
                "hybrid_traditional": "ğŸ”",
                "graph_rag": "ğŸ•¸ï¸", 
                "combined": "ğŸ”„"
            }
            strategy_icon = strategy_icons.get(analysis.recommended_strategy.value, "â“")
            print(f"{strategy_icon} ä½¿ç”¨ç­–ç•¥: {analysis.recommended_strategy.value}")
            print(f"ğŸ“Š å¤æ‚åº¦: {analysis.query_complexity:.2f}, å…³ç³»å¯†é›†åº¦: {analysis.relationship_intensity:.2f}")
            
            # 3. æ˜¾ç¤ºæ£€ç´¢ç»“æœä¿¡æ¯
            if relevant_docs:
                doc_info = []
                for doc in relevant_docs:
                    recipe_name = doc.metadata.get('recipe_name', 'æœªçŸ¥å†…å®¹')
                    search_type = doc.metadata.get('search_type', doc.metadata.get('route_strategy', 'unknown'))
                    score = doc.metadata.get('final_score', doc.metadata.get('relevance_score', 0))
                    doc_info.append(f"{recipe_name}({search_type}, {score:.3f})")
                
                print(f"ğŸ“‹ æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£: {', '.join(doc_info[:3])}")
                if len(doc_info) > 3:
                    print(f"    ç­‰ {len(relevant_docs)} ä¸ªç»“æœ...")
            else:
                return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„çƒ¹é¥ªä¿¡æ¯ã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜ã€‚"
            
            # 4. ç”Ÿæˆå›ç­”
            print("ğŸ¯ æ™ºèƒ½ç”Ÿæˆå›ç­”...")
            
            if stream:
                try:
                    for chunk_text in self.generation_module.generate_adaptive_answer_stream(question, relevant_docs):
                        print(chunk_text, end="", flush=True)
                    print("\n")
                    result = "æµå¼è¾“å‡ºå®Œæˆ"
                except Exception as stream_error:
                    logger.error(f"æµå¼è¾“å‡ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {stream_error}")
                    print(f"\nâš ï¸ æµå¼è¾“å‡ºä¸­æ–­ï¼Œåˆ‡æ¢åˆ°æ ‡å‡†æ¨¡å¼...")
                    # ä½¿ç”¨éæµå¼ä½œä¸ºåå¤‡
                    result = self.generation_module.generate_adaptive_answer(question, relevant_docs)
            else:
                result = self.generation_module.generate_adaptive_answer(question, relevant_docs)
            
            # 5. æ€§èƒ½ç»Ÿè®¡
            end_time = time.time()
            print(f"\nâ±ï¸ é—®ç­”å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
            
            return result, analysis
            
        except Exception as e:
            logger.error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}", None

    def _get_query_embedding(self, query: str):
        """è·å–æŸ¥è¯¢çš„å‘é‡è¡¨ç¤ºï¼ˆç”¨äºè¯­ä¹‰ç¼“å­˜ï¼‰"""
        try:
            if hasattr(self.index_module, 'embedding_model'):
                # ä½¿ç”¨ç°æœ‰çš„embeddingæ¨¡å‹
                return self.index_module.embedding_model.encode([query])[0]
            return None
        except Exception as e:
            logger.warning(f"è·å–æŸ¥è¯¢å‘é‡å¤±è´¥: {e}")
            return None

    def _calculate_similarity(self, embedding1, embedding2):
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            import numpy as np
            dot_product = np.dot(embedding1, embedding2)
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            return dot_product / (norm1 * norm2)
        except:
            return 0.0

    def _check_semantic_cache(self, query: str, session_id: str = None):
        """æ£€æŸ¥ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç›¸ä¼¼æŸ¥è¯¢"""
        if not session_id or session_id not in self.session_caches:
            return None

        session_cache = self.session_caches[session_id]
        session_embeddings = self.session_embeddings.get(session_id, {})

        if not session_cache:
            return None

        query_embedding = self._get_query_embedding(query)
        if query_embedding is None:
            return None

        # æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ç¼“å­˜æŸ¥è¯¢
        best_similarity = 0
        best_response = None

        for cached_query, cached_data in session_cache.items():
            cached_embedding = session_embeddings.get(cached_query)
            if cached_embedding is not None:
                similarity = self._calculate_similarity(query_embedding, cached_embedding)
                if similarity > best_similarity and similarity >= self.cache_threshold:
                    best_similarity = similarity
                    best_response = cached_data['response']

        if best_response:
            logger.info(f"ğŸ¯ ä¼šè¯ç¼“å­˜å‘½ä¸­! Session: {session_id}, ç›¸ä¼¼åº¦: {best_similarity:.3f}")
            return best_response

        return None

    def _add_to_semantic_cache(self, query: str, response: str, session_id: str = None):
        """å°†æŸ¥è¯¢-ç­”æ¡ˆå¯¹æ·»åŠ åˆ°ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜"""
        try:
            if not session_id:
                return

            # åˆå§‹åŒ–ä¼šè¯ç¼“å­˜
            if session_id not in self.session_caches:
                self.session_caches[session_id] = {}
                self.session_embeddings[session_id] = {}

            session_cache = self.session_caches[session_id]
            session_embeddings = self.session_embeddings[session_id]

            # é™åˆ¶ä¼šè¯ç¼“å­˜å¤§å°
            if len(session_cache) >= self.max_session_cache_size:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = next(iter(session_cache))
                del session_cache[oldest_key]
                del session_embeddings[oldest_key]

            query_embedding = self._get_query_embedding(query)
            if query_embedding is not None:
                session_cache[query] = {
                    'response': response,
                    'timestamp': datetime.now()
                }
                session_embeddings[query] = query_embedding
                logger.info(f"ğŸ’¾ å·²ç¼“å­˜åˆ°ä¼šè¯ {session_id}: {query[:50]}...")
        except Exception as e:
            logger.warning(f"ä¼šè¯ç¼“å­˜æ·»åŠ å¤±è´¥: {e}")

    def _add_to_context(self, session_id: str, user_message: str, ai_response: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¼šè¯ä¸Šä¸‹æ–‡"""
        try:
            if not session_id:
                return

            if session_id not in self.session_contexts:
                self.session_contexts[session_id] = []

            context = self.session_contexts[session_id]

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å’ŒAIå›å¤
            context.append({
                'role': 'user',
                'content': user_message,
                'timestamp': datetime.now()
            })
            context.append({
                'role': 'assistant',
                'content': ai_response,
                'timestamp': datetime.now()
            })

            # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
            if len(context) > self.max_context_length * 2:  # *2 å› ä¸ºæ¯è½®å¯¹è¯æœ‰ä¸¤æ¡æ¶ˆæ¯
                context = context[-(self.max_context_length * 2):]
                self.session_contexts[session_id] = context

            logger.info(f"ğŸ“ å·²æ·»åŠ ä¸Šä¸‹æ–‡åˆ°ä¼šè¯ {session_id}, å½“å‰é•¿åº¦: {len(context)}")
        except Exception as e:
            logger.warning(f"ä¸Šä¸‹æ–‡æ·»åŠ å¤±è´¥: {e}")

    def _get_context_for_query(self, session_id: str, current_query: str):
        """è·å–ä¼šè¯ä¸Šä¸‹æ–‡ï¼Œç”¨äºå¢å¼ºå½“å‰æŸ¥è¯¢"""
        try:
            if not session_id or session_id not in self.session_contexts:
                return current_query

            context = self.session_contexts[session_id]
            if not context:
                return current_query

            # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æŸ¥è¯¢
            context_text = ""
            for msg in context[-6:]:  # åªå–æœ€è¿‘3è½®å¯¹è¯
                role = "ç”¨æˆ·" if msg['role'] == 'user' else "åŠ©æ‰‹"
                context_text += f"{role}: {msg['content'][:100]}...\n"

            enhanced_query = f"åŸºäºä»¥ä¸‹å¯¹è¯ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n{context_text}\nå½“å‰é—®é¢˜: {current_query}"
            logger.info(f"ğŸ”— å·²ä¸ºä¼šè¯ {session_id} æ·»åŠ ä¸Šä¸‹æ–‡ï¼ŒæŸ¥è¯¢é•¿åº¦: {len(enhanced_query)}")
            return enhanced_query

        except Exception as e:
            logger.warning(f"ä¸Šä¸‹æ–‡è·å–å¤±è´¥: {e}")
            return current_query

    def run_web_service(self):
        """è¿è¡ŒWebæœåŠ¡æ¨¡å¼"""
        if not self.system_ready:
            print("âŒ ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†åº“")
            return
            
        try:
            from flask import Flask, request, jsonify, Response
            from flask_cors import CORS
            import json
            
            app = Flask(__name__)
            CORS(app, origins=["http://localhost", "http://localhost:3000", "http://127.0.0.1:3000"],
                 methods=['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
                 allow_headers=['Content-Type', 'Authorization'])

            # æ·»åŠ é™æ€æ–‡ä»¶æœåŠ¡
            @app.route('/static/<path:filename>')
            def serve_static(filename):
                """æä¾›é™æ€æ–‡ä»¶æœåŠ¡"""
                import os
                from flask import send_from_directory

                # å®‰å…¨æ£€æŸ¥ï¼Œé˜²æ­¢è·¯å¾„éå†æ”»å‡»
                if '..' in filename or filename.startswith('/'):
                    return "Invalid path", 400

                file_path = os.path.join('.', filename)
                if os.path.exists(file_path):
                    directory = os.path.dirname(file_path)
                    filename_only = os.path.basename(file_path)
                    return send_from_directory(directory, filename_only)
                else:
                    return "File not found", 404


            
            @app.route('/health', methods=['GET'])
            def health_check():
                return jsonify({"status": "healthy", "system_ready": self.system_ready})
            
            @app.route('/api/chat', methods=['POST'])
            def chat():
                try:
                    data = request.get_json()
                    query = data.get('message', '')
                    
                    if not query:
                        return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400

                    # è·å–ä¼šè¯IDï¼ˆå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆä¸€ä¸ªï¼‰
                    import time as time_module
                    session_id = data.get('session_id', f"session_{int(time_module.time())}")

                    # ğŸš€ é¦–å…ˆæ£€æŸ¥ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜
                    cached_response = self._check_semantic_cache(query, session_id)
                    if cached_response:
                        # å³ä½¿æ˜¯ç¼“å­˜å‘½ä¸­ï¼Œä¹Ÿè¦æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                        self._add_to_context(session_id, query, cached_response)
                        return jsonify({
                            "response": cached_response,
                            "query": query,
                            "session_id": session_id,
                            "timestamp": str(datetime.now()),
                            "from_cache": True
                        })

                    # ğŸ”— è·å–ä¸Šä¸‹æ–‡å¢å¼ºçš„æŸ¥è¯¢
                    enhanced_query = self._get_context_for_query(session_id, query)

                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®Œæ•´çš„RAGæµç¨‹
                    documents, analysis = self.query_router.route_query(
                        query=enhanced_query,
                        top_k=self.config.top_k
                    )
                    # ä½¿ç”¨ç”Ÿæˆæ¨¡å—ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
                    response = self.generation_module.generate_adaptive_answer(enhanced_query, documents)

                    # å°†ç»“æœæ·»åŠ åˆ°ä¼šè¯ç¼“å­˜å’Œä¸Šä¸‹æ–‡
                    self._add_to_semantic_cache(query, response, session_id)
                    self._add_to_context(session_id, query, response)
                    
                    return jsonify({
                        "response": response,
                        "query": query,
                        "timestamp": str(datetime.now())
                    })
                    
                except Exception as e:
                    logger.error(f"Chat APIé”™è¯¯: {e}")
                    return jsonify({"error": str(e)}), 500
            
            @app.route('/api/chat/stream', methods=['POST'])
            def chat_stream():
                try:
                    data = request.get_json()
                    query = data.get('message', '')
                    session_id = data.get('session_id', '')

                    if not query:
                        return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400

                    def generate():
                        try:
                            # è·å–ä¼šè¯ID
                            import time as time_module
                            session_id = data.get('session_id', f"session_{int(time_module.time())}")

                            # ğŸš€ é¦–å…ˆæ£€æŸ¥ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜
                            cached_response = self._check_semantic_cache(query, session_id)
                            if cached_response:
                                # ç¼“å­˜å‘½ä¸­ï¼Œå¿«é€Ÿè¿”å›
                                self._add_to_context(session_id, query, cached_response)
                                import json
                                chunk_size = 3
                                for i in range(0, len(cached_response), chunk_size):
                                    chunk = cached_response[i:i+chunk_size]
                                    data_obj = {"chunk": chunk, "from_cache": True}
                                    yield f"data: {json.dumps(data_obj)}\n\n"
                                    time.sleep(0.02)  # æ›´å¿«çš„æµå¼å“åº”
                                yield f"data: [DONE]\n\n"
                                return

                            # ğŸ”— è·å–ä¸Šä¸‹æ–‡å¢å¼ºçš„æŸ¥è¯¢
                            enhanced_query = self._get_context_for_query(session_id, query)

                            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®Œæ•´çš„RAGæµç¨‹
                            documents, analysis = self.query_router.route_query(
                                query=enhanced_query,
                                top_k=self.config.top_k
                            )

                            # ğŸš€ ä½¿ç”¨çœŸæ­£çš„æµå¼ç”Ÿæˆ
                            import json
                            full_response = ""

                            for chunk in self.generation_module.generate_adaptive_answer_stream(enhanced_query, documents):
                                full_response += chunk
                                data_obj = {"chunk": chunk}
                                yield f"data: {json.dumps(data_obj)}\n\n"

                            # å°†å®Œæ•´ç»“æœæ·»åŠ åˆ°ä¼šè¯ç¼“å­˜å’Œä¸Šä¸‹æ–‡
                            self._add_to_semantic_cache(query, full_response, session_id)
                            self._add_to_context(session_id, query, full_response)

                            # å‘é€ç»“æŸæ ‡è®°
                            yield f"data: [DONE]\n\n"

                        except Exception as e:
                            logger.error(f"Stream APIé”™è¯¯: {e}")
                            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
                            data_obj = {"chunk": error_msg}
                            yield f"data: {json.dumps(data_obj)}\n\n"
                            yield f"data: [DONE]\n\n"

                    response = Response(generate(), mimetype='text/event-stream')
                    response.headers['Cache-Control'] = 'no-cache'
                    response.headers['Connection'] = 'keep-alive'
                    response.headers['Access-Control-Allow-Origin'] = '*'
                    response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
                    return response

                except Exception as e:
                    logger.error(f"Stream APIé”™è¯¯: {e}")
                    return jsonify({"error": str(e)}), 500
            
            @app.route('/api/stats', methods=['GET'])
            def get_stats():
                try:
                    stats = self.data_module.get_statistics()
                    return jsonify(stats)
                except Exception as e:
                    return jsonify({"error": str(e)}), 500

            # èœè°±è¯¦æƒ…API
            @app.route('/api/recipes/<recipe_id>', methods=['GET'])
            def get_recipe_detail(recipe_id):
                """è·å–èœè°±è¯¦æƒ…"""
                try:
                    recipe_detail = self._get_recipe_detail_from_db(recipe_id)

                    if recipe_detail:
                        return jsonify({
                            "success": True,
                            "data": recipe_detail,
                            "message": "è·å–èœè°±è¯¦æƒ…æˆåŠŸ"
                        })
                    else:
                        return jsonify({
                            "success": False,
                            "message": "èœè°±ä¸å­˜åœ¨",
                            "data": None
                        }), 404

                except Exception as e:
                    logger.error(f"è·å–èœè°±è¯¦æƒ…å¤±è´¥: {e}")
                    return jsonify({
                        "success": False,
                        "message": f"è·å–èœè°±è¯¦æƒ…å¤±è´¥: {str(e)}",
                        "data": None
                    }), 500

            @app.route('/api/recipes/recommendations', methods=['POST'])
            def get_recommendations():
                try:
                    data = request.get_json() or {}

                    # å…¼å®¹ä¸åŒçš„è¯·æ±‚æ ¼å¼
                    query = data.get('query', 'æ¨èä¸€äº›èœè°±')
                    limit = data.get('limit', 3)
                    preferences = data.get('preferences', {})

                    # å¦‚æœæœ‰ç”¨æˆ·åå¥½ï¼Œæ„å»ºæ›´å…·ä½“çš„æŸ¥è¯¢
                    if preferences:
                        dietary_restrictions = preferences.get('dietaryRestrictions', [])
                        favorite_cuisines = preferences.get('favoriteCuisines', [])
                        cooking_skill = preferences.get('cookingSkill', 'beginner')

                        if dietary_restrictions or favorite_cuisines:
                            query_parts = ["æ¨èä¸€äº›"]
                            if favorite_cuisines:
                                query_parts.append(f"{','.join(favorite_cuisines)}")
                            if dietary_restrictions:
                                query_parts.append(f"é€‚åˆ{','.join(dietary_restrictions)}çš„")
                            if cooking_skill == 'beginner':
                                query_parts.append("ç®€å•æ˜“åšçš„")
                            query_parts.append("èœè°±")
                            query = "".join(query_parts)

                    # è·å–æœ‰å›¾ç‰‡çš„éšæœºæ¨èèœè°±
                    recipes = self._get_random_recipes_with_images(limit)

                    return jsonify({
                        "success": True,
                        "data": recipes,
                        "total": len(recipes),
                        "query": query
                    })
                    
                except Exception as e:
                    logger.error(f"è·å–æ¨èå¤±è´¥: {e}")
                    return jsonify({"error": str(e)}), 500
            


            
            print("ğŸš€ å¯åŠ¨WebæœåŠ¡...")
            print(f"ğŸ“Š å¥åº·æ£€æŸ¥: http://localhost:8000/health")
            print(f"ğŸ’¬ èŠå¤©API: http://localhost:8000/api/chat")
            print(f"ğŸŒŠ æµå¼èŠå¤©: http://localhost:8000/api/chat/stream")
            print(f"ğŸ½ï¸ èœè°±æ¨è: http://localhost:8000/api/recipes/recommendations")
            print(f"ğŸ“– èœè°±è¯¦æƒ…: http://localhost:8000/api/recipes/<recipe_id>")
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯: http://localhost:8000/api/stats")
            
            # å¯åŠ¨Flaskåº”ç”¨
            app.run(host='0.0.0.0', port=8000, debug=False)
            
        except ImportError:
            print("âŒ Flaskæœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨WebæœåŠ¡")
            print("è¯·è¿è¡Œ: pip install flask")
        except Exception as e:
            logger.error(f"WebæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
            print(f"âŒ WebæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
    
    def _get_featured_recipes_from_db(self, limit=6):
        """ä»å›¾æ•°æ®åº“è·å–ç²¾é€‰æ¨èèœè°±"""
        try:
            if not hasattr(self, 'graph_rag_retrieval') or not self.graph_rag_retrieval.driver:
                logger.warning("å›¾æ•°æ®åº“è¿æ¥ä¸å¯ç”¨ï¼Œè¿”å›ç©ºç»“æœ")
                return []

            with self.graph_rag_retrieval.driver.session() as session:
                # æŸ¥è¯¢è¯„åˆ†è¾ƒé«˜ã€æ¯”è¾ƒå—æ¬¢è¿çš„èœè°±
                cypher_query = """
                MATCH (r:Recipe)
                WHERE r.nodeId >= '200000000'
                OPTIONAL MATCH (r)-[:BELONGS_TO_CATEGORY]->(c:Category)
                WITH r, c
                RETURN
                    r.nodeId as id,
                    r.name as name,
                    COALESCE(r.description, 'ç¾å‘³å¯å£çš„ç»å…¸èœè°±') as description,
                    COALESCE(c.name, r.category, 'å®¶å¸¸èœ') as category,
                    COALESCE(r.difficulty, 'â˜…â˜…â˜…') as difficulty_stars,
                    COALESCE(r.cookingTime, 30) as cookingTime,
                    COALESCE(r.prepTime, 15) as prepTime,
                    COALESCE(r.servings, 2) as servings,
                    COALESCE(r.tags, []) as tags,
                    COALESCE(r.rating, 4.5) as rating
                ORDER BY
                    CASE WHEN r.rating IS NOT NULL THEN r.rating ELSE 4.5 END DESC,
                    r.name
                LIMIT $limit
                """

                result = session.run(cypher_query, {"limit": limit})
                recipes = []

                for record in result:
                    # è½¬æ¢éš¾åº¦æ˜Ÿçº§ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                    difficulty_stars = record.get('difficulty_stars', 'â˜…â˜…â˜…')
                    star_count = difficulty_stars.count('â˜…')
                    if star_count <= 2:
                        difficulty = 'easy'
                    elif star_count <= 3:
                        difficulty = 'medium'
                    else:
                        difficulty = 'hard'

                    recipe = {
                        "id": record.get('id'),
                        "name": record.get('name'),
                        "description": record.get('description'),
                        "category": record.get('category'),
                        "imageUrl": f"https://via.placeholder.com/300x200?text={record.get('name', 'Recipe')}",
                        "cookingTime": int(record.get('cookingTime', 30)),
                        "prepTime": int(record.get('prepTime', 15)),
                        "servings": int(record.get('servings', 2)),
                        "difficulty": difficulty,
                        "rating": float(record.get('rating', 4.5)),
                        "tags": record.get('tags', []),
                        "ingredients": [],
                        "steps": [],
                        "createdAt": "2024-01-01T00:00:00Z",
                        "updatedAt": "2024-01-01T00:00:00Z"
                    }
                    recipes.append(recipe)

                logger.info(f"ä»æ•°æ®åº“è·å–åˆ° {len(recipes)} ä¸ªæ¨èèœè°±")
                return recipes

        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–æ¨èèœè°±å¤±è´¥: {e}")
            return []

    def _get_fallback_recommendations(self, limit=6):
        """å¤‡ç”¨æ¨èèœè°±ï¼ˆå½“æ•°æ®åº“æŸ¥è¯¢å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        fallback_recipes = [
            {
                "id": "fallback_001",
                "name": "çº¢çƒ§è‚‰",
                "description": "è‚¥ç˜¦ç›¸é—´ï¼Œå…¥å£å³åŒ–çš„ç»å…¸å®¶å¸¸èœ",
                "category": "å®¶å¸¸èœ",
                "imageUrl": "https://via.placeholder.com/300x200?text=çº¢çƒ§è‚‰",
                "cookingTime": 60,
                "prepTime": 15,
                "servings": 4,
                "difficulty": "medium",
                "rating": 4.8,
                "tags": ["å®¶å¸¸èœ", "ä¸‹é¥­", "ç»å…¸"],
                "ingredients": [],
                "steps": [],
                "createdAt": "2024-01-01T00:00:00Z",
                "updatedAt": "2024-01-01T00:00:00Z"
            },
            {
                "id": "fallback_002",
                "name": "è¥¿çº¢æŸ¿é¸¡è›‹",
                "description": "é…¸ç”œå¼€èƒƒï¼Œè¥å…»ä¸°å¯Œçš„å›½æ°‘èœ",
                "category": "å®¶å¸¸èœ",
                "imageUrl": "https://via.placeholder.com/300x200?text=è¥¿çº¢æŸ¿é¸¡è›‹",
                "cookingTime": 15,
                "prepTime": 10,
                "servings": 2,
                "difficulty": "easy",
                "rating": 4.6,
                "tags": ["ç®€å•", "è¥å…»", "ä¸‹é¥­"],
                "ingredients": [],
                "steps": [],
                "createdAt": "2024-01-01T00:00:00Z",
                "updatedAt": "2024-01-01T00:00:00Z"
            }
        ]
        return fallback_recipes[:limit]

    def _get_random_recipes_with_images(self, limit=3):
        """ä»é¢„ç”Ÿæˆçš„ç´¢å¼•æ–‡ä»¶è·å–éšæœºçš„æœ‰å›¾ç‰‡çš„èœè°±æ¨è"""
        try:
            import json
            import random
            import os

            # è¯»å–é¢„ç”Ÿæˆçš„èœè°±ç´¢å¼•æ–‡ä»¶
            index_file = "data/recipes_with_images.json"

            if not os.path.exists(index_file):
                logger.warning(f"èœè°±ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
                return self._get_fallback_recommendations(limit)

            with open(index_file, 'r', encoding='utf-8') as f:
                recipes_data = json.load(f)

            if not recipes_data:
                logger.warning("èœè°±ç´¢å¼•æ–‡ä»¶ä¸ºç©º")
                return self._get_fallback_recommendations(limit)

            # è½¬æ¢ä¸ºAPIæ ¼å¼
            recipes_with_images = []
            for i, recipe_data in enumerate(recipes_data):
                # ç”Ÿæˆéšæœºéš¾åº¦
                difficulties = ['easy', 'medium', 'hard']
                difficulty = random.choice(difficulties)

                # å¤„ç†å›¾ç‰‡URL
                image_url = recipe_data.get('image_url', '')
                if image_url and not image_url.startswith('http'):
                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                    file_path = recipe_data.get('file_path', '')
                    if file_path:
                        # è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•
                        import os
                        file_dir = os.path.dirname(file_path)
                        # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼ˆå»æ‰ ./ å‰ç¼€ï¼‰
                        if image_url.startswith('./'):
                            image_url = image_url[2:]
                        # æ„å»ºGitHub LFSåª’ä½“URL
                        # ä»file_pathä¸­æå–dishesç›®å½•åçš„è·¯å¾„
                        # ä¾‹å¦‚: "data\\dishes\\vegetable_dish\\é¸¡è›‹ç¾¹\\å¾®æ³¢ç‚‰é¸¡è›‹ç¾¹.md" -> "dishes/vegetable_dish/é¸¡è›‹ç¾¹/"
                        if 'dishes' in file_path:
                            # æ‰¾åˆ°dishesçš„ä½ç½®ï¼Œæå–dishesåé¢çš„è·¯å¾„
                            dishes_index = file_path.find('dishes')
                            if dishes_index != -1:
                                # æå–ä»disheså¼€å§‹åˆ°æ–‡ä»¶åä¹‹å‰çš„è·¯å¾„
                                path_after_dishes = file_path[dishes_index:].replace('\\', '/')
                                # ç§»é™¤æ–‡ä»¶åï¼Œåªä¿ç•™ç›®å½•è·¯å¾„
                                dir_path = '/'.join(path_after_dishes.split('/')[:-1])
                                github_path = f"{dir_path}/{image_url}"
                            else:
                                github_path = image_url
                        else:
                            github_path = image_url

                        # ä½¿ç”¨æ‚¨forkçš„HowToCookä»“åº“çš„GitHub LFSåª’ä½“URL
                        image_url = f"https://media.githubusercontent.com/media/FutureUnreal/HowToCook/master/{github_path}"
                        logger.info(f"è½¬æ¢åçš„GitHubå›¾ç‰‡URL: {image_url}")

                recipe = {
                    "id": f"recipe_{i + 1}",
                    "name": recipe_data.get('name', 'æœªçŸ¥èœè°±'),
                    "description": recipe_data.get('description', 'ç¾å‘³å¯å£çš„ç»å…¸èœè°±'),
                    "category": recipe_data.get('category', 'å®¶å¸¸èœ'),
                    "imageUrl": image_url or f"https://via.placeholder.com/300x200?text={recipe_data.get('name', 'Recipe')}",
                    "cookingTime": recipe_data.get('cooking_time', 30),
                    "prepTime": 15,
                    "servings": 2,
                    "difficulty": difficulty,
                    "tags": recipe_data.get('tags', []),
                    "ingredients": [],
                    "steps": [],
                    "markdownPath": recipe_data.get('file_path', ''),
                    "createdAt": "2024-01-01T00:00:00Z",
                    "updatedAt": "2024-01-01T00:00:00Z"
                }
                recipes_with_images.append(recipe)

            # éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„èœè°±
            if len(recipes_with_images) >= limit:
                selected_recipes = random.sample(recipes_with_images, limit)
            else:
                selected_recipes = recipes_with_images[:limit]
                # å¦‚æœä¸å¤Ÿï¼Œç”¨å¤‡ç”¨æ•°æ®è¡¥å……
                if len(selected_recipes) < limit:
                    fallback = self._get_fallback_recommendations(limit - len(selected_recipes))
                    selected_recipes.extend(fallback)

            logger.info(f"ä»ç´¢å¼•æ–‡ä»¶åŠ è½½ {len(recipes_with_images)} ä¸ªèœè°±ï¼Œè¿”å› {len(selected_recipes)} ä¸ª")
            return selected_recipes

        except Exception as e:
            logger.error(f"ä»ç´¢å¼•æ–‡ä»¶è·å–èœè°±å¤±è´¥: {e}")
            return self._get_fallback_recommendations(limit)



    def _get_recipe_detail_from_db(self, recipe_id):
        """ä»ç´¢å¼•æ–‡ä»¶å’ŒåŸå§‹æ–‡ä»¶è·å–èœè°±è¯¦æƒ…"""
        try:
            import json
            import os

            # é¦–å…ˆå°è¯•ä»ç´¢å¼•æ–‡ä»¶è·å–èœè°±ä¿¡æ¯
            index_file = "data/recipes_with_images.json"

            if os.path.exists(index_file):
                with open(index_file, 'r', encoding='utf-8') as f:
                    recipes_data = json.load(f)

                # æŸ¥æ‰¾å¯¹åº”çš„èœè°±ï¼ˆrecipe_idæ ¼å¼ä¸º recipe_Nï¼‰
                recipe_index = None
                if recipe_id.startswith('recipe_'):
                    try:
                        recipe_index = int(recipe_id.split('_')[1]) - 1
                    except (ValueError, IndexError):
                        pass

                if recipe_index is not None and 0 <= recipe_index < len(recipes_data):
                    recipe_data = recipes_data[recipe_index]

                    # è¯»å–Markdownæ–‡ä»¶å†…å®¹
                    markdown_content = None
                    file_path = recipe_data.get('file_path', '')
                    if file_path and os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            markdown_content = f.read()

                    # å¤„ç†å›¾ç‰‡URL - ä½¿ç”¨GitHub Raw URL
                    image_url = recipe_data.get('image_url', '')
                    if image_url and not image_url.startswith('http'):
                        if file_path:
                            file_dir = os.path.dirname(file_path)
                            if image_url.startswith('./'):
                                image_url = image_url[2:]
                            # æ„å»ºGitHub LFSåª’ä½“URL
                            # ä»file_pathä¸­æå–dishesç›®å½•åçš„è·¯å¾„
                            if 'dishes' in file_path:
                                # æ‰¾åˆ°dishesçš„ä½ç½®ï¼Œæå–dishesåé¢çš„è·¯å¾„
                                dishes_index = file_path.find('dishes')
                                if dishes_index != -1:
                                    # æå–ä»disheså¼€å§‹åˆ°æ–‡ä»¶åä¹‹å‰çš„è·¯å¾„
                                    path_after_dishes = file_path[dishes_index:].replace('\\', '/')
                                    # ç§»é™¤æ–‡ä»¶åï¼Œåªä¿ç•™ç›®å½•è·¯å¾„
                                    dir_path = '/'.join(path_after_dishes.split('/')[:-1])
                                    github_path = f"{dir_path}/{image_url}"
                                else:
                                    github_path = image_url
                            else:
                                github_path = image_url

                            # ä½¿ç”¨æ‚¨forkçš„HowToCookä»“åº“çš„GitHub LFSåª’ä½“URL
                            github_raw_url = f"https://media.githubusercontent.com/media/FutureUnreal/HowToCook/master/{github_path}"
                            image_url = github_raw_url
                            logger.info(f"è¯¦æƒ…é¡µGitHubå›¾ç‰‡URL: {image_url}")

                    # æ„å»ºè¯¦æƒ…æ•°æ®
                    recipe_detail = {
                        "id": recipe_id,
                        "name": recipe_data.get('name', 'æœªçŸ¥èœè°±'),
                        "description": recipe_data.get('description', 'ç¾å‘³å¯å£çš„ç»å…¸èœè°±'),
                        "category": recipe_data.get('category', 'å®¶å¸¸èœ'),
                        "imageUrl": image_url or f"https://via.placeholder.com/600x400?text={recipe_data.get('name', 'Recipe')}",
                        "cookingTime": recipe_data.get('cooking_time', 30),
                        "prepTime": 15,
                        "servings": 2,
                        "difficulty": "medium",
                        "tags": recipe_data.get('tags', []),
                        "ingredients": [],  # å¯ä»¥ä»Markdownè§£æ
                        "steps": [],  # å¯ä»¥ä»Markdownè§£æ
                        "markdownContent": markdown_content,
                        "createdAt": "2024-01-01T00:00:00Z",
                        "updatedAt": "2024-01-01T00:00:00Z"
                    }

                    return recipe_detail

            # å¦‚æœç´¢å¼•æ–‡ä»¶æ–¹æ³•å¤±è´¥ï¼Œè¿”å›None
            logger.warning(f"æ— æ³•æ‰¾åˆ°èœè°±: {recipe_id}")
            return None

        except Exception as e:
            logger.error(f"è·å–èœè°±è¯¦æƒ…å¤±è´¥: {e}")
            return None

    def _read_recipe_markdown(self, recipe_name):
        """è¯»å–èœè°±çš„åŸå§‹Markdownæ–‡ä»¶"""
        try:
            import os
            import glob

            # åœ¨data/dishesç›®å½•ä¸­æœç´¢åŒ¹é…çš„Markdownæ–‡ä»¶
            dishes_dir = "data/dishes"
            if not os.path.exists(dishes_dir):
                return None

            # æœç´¢åŒ…å«èœè°±åç§°çš„Markdownæ–‡ä»¶
            for root, dirs, files in os.walk(dishes_dir):
                for file in files:
                    if file.endswith('.md') and recipe_name in file:
                        file_path = os.path.join(root, file)
                        with open(file_path, 'r', encoding='utf-8') as f:
                            return f.read()

            return None

        except Exception as e:
            logger.error(f"è¯»å–èœè°±Markdownæ–‡ä»¶å¤±è´¥: {e}")
            return None

    def _extract_image_from_markdown(self, markdown_content):
        """ä»Markdownå†…å®¹ä¸­æå–å›¾ç‰‡URL"""
        if not markdown_content:
            return None

        try:
            import re
            # åŒ¹é…Markdownå›¾ç‰‡è¯­æ³• ![alt](url)
            image_pattern = r'!\[.*?\]\((.*?)\)'
            matches = re.findall(image_pattern, markdown_content)

            if matches:
                # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å›¾ç‰‡URL
                return matches[0]

            return None

        except Exception as e:
            logger.error(f"æå–å›¾ç‰‡URLå¤±è´¥: {e}")
            return None

    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.data_module:
            self.data_module.close()
        if self.traditional_retrieval:
            self.traditional_retrieval.close()
        if self.graph_rag_retrieval:
            self.graph_rag_retrieval.close()
        if self.index_module:
            self.index_module.close()

def main():
    """ä¸»å‡½æ•°"""
    try:
        print("å¯åŠ¨é«˜çº§å›¾RAGç³»ç»Ÿ...")
        
        # åˆ›å»ºé«˜çº§å›¾RAGç³»ç»Ÿ
        rag_system = AdvancedGraphRAGSystem()
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        rag_system.initialize_system()
        
        # æ„å»ºçŸ¥è¯†åº“
        rag_system.build_knowledge_base()
        
        # å¯åŠ¨WebæœåŠ¡ï¼ˆDockerç¯å¢ƒï¼‰
        rag_system.run_web_service()
        
    except Exception as e:
        logger.error(f"ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main() 